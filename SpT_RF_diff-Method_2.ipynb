{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "50f723fd-4f3e-4d81-a68e-2959d1c1bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "These receptive fields are derived from scale-space theory, specifically in the paper `Normative theory of visual receptive fields by Lindeberg, 2021 <https://www.sciencedirect.com/science/article/pii/S2405844021000025>`_.\n",
    "\n",
    "For use in spiking / binary signals, see the paper on `Translation and Scale Invariance for Event-Based Object tracking by Pedersen et al., 2023 <https://dl.acm.org/doi/10.1145/3584954.3584996>`_\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Tuple, Union, Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def gaussian_kernel(x, s, c):\n",
    "    \"\"\"\n",
    "    Efficiently creates a 2d gaussian kernel.\n",
    "\n",
    "    Arguments:\n",
    "      x (torch.Tensor): A 2-d matrix\n",
    "      s (float): The variance of the gaussian\n",
    "      c (torch.Tensor): A 2x2 covariance matrix describing the eccentricity of the gaussian\n",
    "    \"\"\"\n",
    "    ci = torch.linalg.inv(c)\n",
    "    cd = torch.linalg.det(c)\n",
    "    fraction = 1 / (2 * torch.pi * s * torch.sqrt(cd))\n",
    "    b = torch.einsum(\"bimj,jk->bik\", -x.unsqueeze(2), ci)\n",
    "    a = torch.einsum(\"bij,bij->bi\", b, x)\n",
    "    return fraction * torch.exp(a / (2 * s))\n",
    "\n",
    "\n",
    "def spatial_receptive_field(\n",
    "    angle, ratio, size: int, scale: float = 2.5, dx: int = 0, dy: int = 0, domain: float = 8\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a (size x size) receptive field kernel\n",
    "\n",
    "    Arguments:\n",
    "      angle (float): The rotation of the kernel in radians\n",
    "      ratio (float): The eccentricity as a ratio\n",
    "      size (int): The size of the square kernel in pixels\n",
    "      scale (float): The scale of the field. Defaults to 2.5\n",
    "      domain (float): The initial coordinates from which the field is sampled. Defaults to 8 (equal to -8 to 8).\n",
    "    \"\"\"\n",
    "    sm = torch.ones(2)\n",
    "    sm[0] = scale\n",
    "    sm[1] = scale*ratio\n",
    "    a = torch.linspace(-domain, domain, size)\n",
    "    r = torch.ones((2,2))\n",
    "    r[0][0] = angle.cos()\n",
    "    r[0][1] = angle.sin()\n",
    "    r[1][0] = -angle.sin()\n",
    "    r[1][1] = angle.cos()    \n",
    "    c = (r * sm) @ (sm * r).T\n",
    "    xs, ys = torch.meshgrid(a, a, indexing=\"xy\")\n",
    "    coo = torch.stack([xs, ys], dim=2)\n",
    "    k = gaussian_kernel(coo, scale, c)\n",
    "    k = _derived_field(k, (dx, dy))\n",
    "    return k / k.sum()\n",
    "\n",
    "\n",
    "def _extract_derivatives(\n",
    "    derivatives: Union[int, List[Tuple[int, int]]]\n",
    ") -> Tuple[List[Tuple[int, int]], int]:\n",
    "    if isinstance(derivatives, int):\n",
    "        if derivatives == 0:\n",
    "            return [(0, 0)], 0\n",
    "        else:\n",
    "            return [\n",
    "                (x, y) for x in range(derivatives + 1) for y in range(derivatives + 1)\n",
    "            ], derivatives\n",
    "    elif isinstance(derivatives, list):\n",
    "        return derivatives, max([max(x, y) for (x, y) in derivatives])\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Derivatives expected either a number or a list of tuples, but got {derivatives}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _derived_field(\n",
    "    field: torch.Tensor, derivatives: Tuple[int, int]\n",
    ") -> torch.Tensor:\n",
    "    out = []\n",
    "    (dx, dy) = derivatives\n",
    "    if dx == 0:\n",
    "        fx = field\n",
    "    else:\n",
    "        fx = field.diff(\n",
    "            dim=0, prepend=torch.zeros(dx, field.shape[1]), n=dx)\n",
    "\n",
    "    if dy == 0:\n",
    "        fy = fx\n",
    "    else:\n",
    "        fy = fx.diff(\n",
    "            dim=1, prepend=torch.zeros(field.shape[0], dy), n=dy)\n",
    "    out.append(fy)\n",
    "    return torch.concat(out)\n",
    "\n",
    "\n",
    "def spatial_receptive_fields_with_derivatives(\n",
    "    gf_attr,\n",
    "    derivative_max: int,\n",
    "    size: int,\n",
    "    min_scale: float = 0.2,\n",
    "    max_scale: float = 1.5,\n",
    "    min_ratio: float = 0.2,\n",
    "    max_ratio: float = 1,\n",
    ") -> torch.Tensor:\n",
    "    r\"\"\"\n",
    "    Creates a number of receptive field with 1st directional derivatives.\n",
    "    The parameters decide the number of combinations to scan over, i. e. the number of receptive fields to generate.\n",
    "    Specifically, we generate ``derivatives * (n_angles * n_scales * (n_ratios - 1) + n_scales)`` fields.\n",
    "    The ``(n_ratios - 1) + n_scales`` terms exist because at ``ratio = 1``, fields are perfectly symmetrical, and there\n",
    "    is therefore no reason to scan over the angles and scales for ``ratio = 1``.\n",
    "    However, ``n_scales`` receptive fields still need to be added (one for each scale-space).\n",
    "    Finally, the ``derivatives *`` term comes from the addition of spatial derivatives.\n",
    "    Arguments:\n",
    "        n_scales (int): Number of scaling combinations (the size of the receptive field) drawn from a logarithmic distribution\n",
    "        n_angles (int): Number of angular combinations (the orientation of the receptive field)\n",
    "        n_ratios (int): Number of eccentricity combinations (how \"flat\" the receptive field is)\n",
    "        size (int): The size of the square kernel in pixels\n",
    "        derivatives (Union[int, List[Tuple[int, int]]]): The spatial derivatives to include. Defaults to 0 (no derivatives).\n",
    "            Can either be a number, in which case 1 + 2 ** n derivatives will be made (except when 0, see below).\n",
    "              Example: `derivatives=0` omits derivatives\n",
    "              Example: `derivatives=1` provides 2 spatial derivatives + 1 without derivation\n",
    "            Or a list of tuples specifying the derivatives in both spatial dimensions\n",
    "              Example: `derivatives=[(0, 0), (1, 2)]` provides two outputs, one without derivation and one :math:`\\partial_x \\partial^2_y`\n",
    "    \"\"\"\n",
    "\n",
    "    def _stack_empty(x):\n",
    "        if len(x) == 0:\n",
    "            return torch.tensor([])\n",
    "        else:\n",
    "            return torch.stack(x)\n",
    "\n",
    "    # We add extra space in both the domain and size to account for the derivatives\n",
    "    domain = 8 + derivative_max * size * 0.5\n",
    "\n",
    "    rings = _stack_empty(\n",
    "        [\n",
    "            spatial_receptive_field(attr[1], attr[2], size=size + 2 * derivative_max, scale=attr[0], dx=attr[3], dy=attr[4], domain=domain)\n",
    "            for attr in gf_attr\n",
    "        ]\n",
    "    )\n",
    "    derived_fields = rings[\n",
    "        :,\n",
    "        derivative_max : size + derivative_max,\n",
    "        derivative_max : size + derivative_max,  # Remove extra space\n",
    "    ]\n",
    "    #derived_fields.sum().backward()\n",
    "    #print(angles.grad)\n",
    "\n",
    "    return derived_fields\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6af83a25-7d29-4ea4-aaaf-103e56228732",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "These receptive fields are derived from scale-space theory, specifically in the paper `Normative theory of visual receptive fields by Lindeberg, 2021 <https://www.sciencedirect.com/science/article/pii/S2405844021000025>`_.\n",
    "\n",
    "For use in spiking / binary signals, see the paper on `Translation and Scale Invariance for Event-Based Object tracking by Pedersen et al., 2023 <https://dl.acm.org/doi/10.1145/3584954.3584996>`_\n",
    "\"\"\"\n",
    "\n",
    "from typing import Callable, List, NamedTuple, Optional, Tuple, Type, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "#from norse.torch.module.leaky_integrator_box import LIBoxCell, LIBoxParameters\n",
    "from norse.torch.module.snn import SNNCell\n",
    "\n",
    "\n",
    "\n",
    "class SpatialReceptiveField2d(torch.nn.Module):\n",
    "    \"\"\"Creates a spatial receptive field as 2-dimensional convolutions.\n",
    "    The parameters decide the number of combinations to scan over, i. e. the number of receptive fields to generate.\n",
    "    Specifically, we generate ``n_scales * n_angles * (n_ratios - 1) + n_scales`` output_channels with aggregation,\n",
    "    and ``in_channels * (n_scales * n_angles * (n_ratios - 1) + n_scales)`` without aggregation.\n",
    "\n",
    "    The ``(n_ratios - 1) + n_scales`` terms exist because at ``ratio = 1``, fields are perfectly symmetrical, and there\n",
    "    is therefore no reason to scan over the angles and scales for ``ratio = 1``.\n",
    "    However, ``n_scales`` receptive field still needs to be added (one for each scale-space).\n",
    "\n",
    "    Parameters:\n",
    "        n_scales (int): Number of scaling combinations (the size of the receptive field) drawn from a logarithmic distribution\n",
    "        n_angles (int): Number of angular combinations (the orientation of the receptive field)\n",
    "        n_ratios (int): Number of eccentricity combinations (how \"flat\" the receptive field is)\n",
    "        size (int): The size of the square kernel in pixels\n",
    "        derivatives (Union[int, List[Tuple[int, int]]]): The number of derivatives to use in the receptive field.\n",
    "        aggregate (bool): If True, sums the input channels over all output channels. If False, every\n",
    "        output channel is mapped to every input channel, which may blow up in complexity.\n",
    "        **kwargs: Arguments passed on to the underlying torch.nn.Conv2d\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        n_scales: int,\n",
    "        n_angles: int,\n",
    "        n_ratios: int,\n",
    "        size: int,\n",
    "        derivatives: Union[int, List[Tuple[int, int]]] = 0,\n",
    "        min_scale: float = 0.2,\n",
    "        max_scale: float = 1.5,\n",
    "        min_ratio: float = 0.2,\n",
    "        max_ratio: float = 1,\n",
    "        aggregate: bool = True,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.aggregate = aggregate\n",
    "        self.size = size\n",
    "        self.derivatives = derivatives\n",
    "        self.in_channels = in_channels\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "        self.angles = torch.linspace(0, torch.pi - torch.pi / n_angles, n_angles, requires_grad=True)\n",
    "        self.ratios = torch.linspace(min_ratio, max_ratio, n_ratios, requires_grad=True)\n",
    "        self.log_scales = torch.linspace(min_scale, max_scale, n_scales, requires_grad=True)\n",
    "        scales = torch.exp(self.log_scales)\n",
    "        \n",
    "        self.update = False\n",
    "        derivative_list, self.derivative_max = _extract_derivatives(self.derivatives)\n",
    "        gf_attr = [[s, a, r, d[0], d[1]] for s in scales for a in self.angles for r in self.ratios for d in derivative_list]\n",
    "        self.gf_attr = torch.tensor(gf_attr, requires_grad=True)\n",
    "        self.fields = spatial_receptive_fields_with_derivatives(\n",
    "            self.gf_attr,\n",
    "            self.derivative_max,\n",
    "            self.size,\n",
    "        )\n",
    "        if self.aggregate:\n",
    "            self.out_channels = self.fields.shape[0]\n",
    "            weights = self.fields.unsqueeze(1).repeat(1, in_channels, 1, 1)\n",
    "        else:\n",
    "            self.out_channels = self.fields.shape[0] * in_channels\n",
    "            empty_weights = torch.zeros(in_channels, self.fields.shape[0], size, size)\n",
    "            weights = []\n",
    "            for i in range(in_channels):\n",
    "                in_weights = empty_weights.clone()\n",
    "                in_weights[i] = self.fields\n",
    "                weights.append(in_weights)\n",
    "            weights = torch.concat(weights, 1).permute(1, 0, 2, 3)\n",
    "        self.conv = torch.nn.Conv2d(in_channels, self.out_channels, size, **kwargs)\n",
    "        self.conv.weight = torch.nn.Parameter(weights, requires_grad=False)\n",
    "        self.conv.weight[:] = weights[:]\n",
    "        print(self.gf_attr.grad)\n",
    "        print(self.angles.grad, self.ratios.grad, self.log_scales.grad)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if self.update:\n",
    "            self.update = False\n",
    "            self.fields = spatial_receptive_fields_with_derivatives(\n",
    "                self.gf_attr,\n",
    "                self.derivative_max,\n",
    "                self.size,\n",
    "            )\n",
    "            if self.aggregate:\n",
    "                self.out_channels = self.fields.shape[0]\n",
    "                weights = self.fields.unsqueeze(1).repeat(1, self.in_channels, 1, 1)\n",
    "            else:\n",
    "                self.out_channels = self.fields.shape[0] * self.in_channels\n",
    "                empty_weights = torch.zeros(self.in_channels, self.fields.shape[0], self.size, self.size)\n",
    "                weights = []\n",
    "                for i in range(self.in_channels):\n",
    "                    in_weights = empty_weights.clone()\n",
    "                    in_weights[i] = self.fields\n",
    "                    weights.append(in_weights)\n",
    "                weights = torch.concat(weights, 1).permute(1, 0, 2, 3)\n",
    "            self.conv = torch.nn.Conv2d(self.in_channels, self.out_channels, self.size, **self.kwargs)\n",
    "            self.conv.weight = torch.nn.Parameter(weights, requires_grad=False)\n",
    "            self.conv.weight[:] = weights[:]\n",
    "        \n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "\n",
    "def diff(model, lr = 0.01):\n",
    "    with torch.no_grad():\n",
    "        model.gf_attr -= model.gf_attr.grad*lr\n",
    "    model.gf_attr.grad.zero_()\n",
    "    model.update = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "09ce6d87-f7dc-4154-9119-4b01737a3177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None None None\n",
      "attr: tensor([[1.2214, 0.0000, 0.2000, 0.0000, 0.0000],\n",
      "        [1.2214, 0.0000, 1.0000, 0.0000, 0.0000],\n",
      "        [1.2214, 1.5708, 0.2000, 0.0000, 0.0000],\n",
      "        [1.2214, 1.5708, 1.0000, 0.0000, 0.0000]], requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  1.2148e-25,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3609e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.2148e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-1.7389e-06,  3.6869e-25, -7.0481e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7389e-06, -1.4722e-12, -7.0481e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -4.9016e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -5.1543e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3609e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[1.2214e+00, 2.5269e-28, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -2.6494e-26, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2429e-09,  0.0000e+00, -2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2429e-09,  2.1176e-22, -2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[1.2214e+00, 5.1763e-28, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07,  4.4781e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.9605e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07,  5.3057e-26, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -4.4911e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07,  5.4240e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -9.9151e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -9.9151e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -9.9151e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07,  4.3273e-26, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.0348e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-1.7389e-06,  1.0660e-24, -7.0481e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7389e-06, -1.4722e-12, -7.0481e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.1008e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.1008e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-1.7389e-06,  1.1934e-24, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7389e-06, -1.4722e-12, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.2943e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -4.6652e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.8278e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[ 1.2214e+00, -2.8278e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-1.7389e-06,  4.5654e-26, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7389e-06, -1.4722e-12, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.8734e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -2.3989e-27, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0486e-08,  0.0000e+00, -4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0486e-08,  4.2352e-22, -4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.8710e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-1.7389e-06, -8.2436e-25, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7389e-06, -1.4722e-12, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.0467e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07,  4.6212e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.5088e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-1.7389e-06,  9.0549e-25, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7389e-06, -1.4722e-12, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.4143e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[ 1.2214e+00, -3.4143e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07,  5.8429e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.9985e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-2.6083e-06, -5.7866e-25, -1.0572e-05,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.6083e-06, -2.2082e-12, -1.0572e-05,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.4199e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-1.7389e-06, -7.1868e-26, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7389e-06, -1.4722e-12, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.3480e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07, -5.9048e-26,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.2890e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[ 1.2214e+00, -3.2890e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[ 1.2214e+00, -3.2890e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2429e-09,  0.0000e+00, -2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2429e-09,  2.1176e-22, -2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.2890e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 1.7389e-06,  8.6140e-25,  7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7389e-06,  1.4722e-12,  7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -4.1504e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -4.9440e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.6560e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -3.5934e-26, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.6200e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -4.1485e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.2052e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 1.7389e-06, -1.4152e-26,  7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7389e-06,  1.4722e-12,  7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.1910e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  7.2880e-26,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2429e-09,  0.0000e+00, -2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2429e-09,  2.1176e-22, -2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.2639e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  6.3512e-26,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.3274e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -1.5244e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.1750e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr: tensor([[ 1.2214e+00, -3.1750e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.1750e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.1750e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[8.6944e-07, 6.3512e-26, 3.5240e-06, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.6944e-07, 7.3608e-13, 3.5240e-06, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -3.2385e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-1.7389e-06, -3.0488e-25, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7389e-06, -1.4722e-12, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.9336e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  3.5934e-26,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.9695e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.9695e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -4.9440e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5728e-08,  0.0000e+00,  6.4036e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5728e-08,  4.2352e-22,  6.4036e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.4751e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -3.5934e-26, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.4392e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -4.1485e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.0244e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 1.7389e-06, -1.4151e-26,  7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7389e-06,  1.4722e-12,  7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.0102e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.0102e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2429e-09,  0.0000e+00, -2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2429e-09,  2.1176e-22, -2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.0102e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.0102e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  7.2881e-26,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.0831e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  6.3512e-26,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.1466e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-2.6083e-06, -5.0890e-25, -1.0572e-05,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.6083e-06, -2.2082e-12, -1.0572e-05,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.6377e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -4.1485e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.2229e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07, -7.0755e-27,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2429e-09,  0.0000e+00, -2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2429e-09,  2.1176e-22, -2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.2158e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  4.1485e-25,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.6306e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0486e-08,  0.0000e+00, -4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0486e-08,  4.2352e-22, -4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.6306e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  3.5934e-26,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.6666e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[ 1.2214e+00, -1.6666e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -4.9440e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.1722e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[8.6944e-07, 3.5934e-26, 3.5240e-06, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.6944e-07, 7.3608e-13, 3.5240e-06, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.2081e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[ 1.2214e+00, -1.2081e-26,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -4.9440e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -7.1370e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-1.7389e-06, -7.1869e-26, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7389e-06, -1.4722e-12, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -6.4183e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07,  5.9047e-26, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -7.0088e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[ 1.2214e+00, -7.0088e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2429e-09,  0.0000e+00, -2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.2429e-09,  2.1176e-22, -2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -7.0088e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07, -5.4798e-25,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.5289e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.5289e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07, -5.9047e-26,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -9.3848e-28,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -9.3848e-28,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[ 1.2214e+00, -9.3848e-28,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[ 1.2214e+00, -9.3848e-28,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -9.3848e-28,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  4.3070e-25,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -5.2455e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[ 1.2214e+00, -5.2455e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr: tensor([[ 1.2214e+00, -5.2455e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  3.5944e-26,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -5.6049e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  7.2881e-26,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0486e-08,  0.0000e+00, -4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0486e-08,  4.2352e-22, -4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -6.3337e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[8.6944e-07, 6.3512e-26, 3.5240e-06, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.6944e-07, 7.3608e-13, 3.5240e-06, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -6.9688e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-2.6083e-06, -5.0890e-25, -1.0572e-05,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.6083e-06, -2.2082e-12, -1.0572e-05,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.8799e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.8799e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  4.1485e-25,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -6.0284e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[ 1.2214e+00, -6.0284e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[8.6944e-07, 3.5934e-26, 3.5240e-06, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.6944e-07, 7.3608e-13, 3.5240e-06, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -6.3877e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -6.3877e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -6.3877e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -6.3877e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -4.9440e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0486e-08,  0.0000e+00, -4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0486e-08,  4.2352e-22, -4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -1.4437e-27,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-1.7389e-06, -7.1869e-26, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5728e-08,  0.0000e+00,  6.4036e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7389e-06, -1.4722e-12, -7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5728e-08,  4.2352e-22,  6.4036e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -7.2501e-28,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 1.7389e-06, -1.1809e-25,  7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7389e-06,  1.4722e-12,  7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[1.2214e+00, 4.5593e-28, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[1.2214e+00, 4.5593e-28, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[1.2214e+00, 4.5593e-28, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 1.7389e-06,  7.1869e-26,  7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0486e-08,  0.0000e+00, -4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7389e-06,  1.4722e-12,  7.0480e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0486e-08,  4.2352e-22, -4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[ 1.2214e+00, -2.6276e-28,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  2.0000e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.2214e+00,  1.5708e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -1.5244e-25, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[1.2214e+00, 1.2616e-27, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "attr: tensor([[1.2214e+00, 1.2616e-27, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -6.3512e-26, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09,  0.0000e+00,  2.1346e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2429e-09, -2.1176e-22,  2.1346e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[1.2214e+00, 1.8968e-27, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 8.6944e-07,  7.2881e-26,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.6944e-07,  7.3608e-13,  3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[1.2214e+00, 1.1680e-27, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08,  0.0000e+00,  4.2693e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0486e-08, -4.2352e-22,  4.2692e-09,  0.0000e+00,  0.0000e+00]])\n",
      "attr: tensor([[1.2214e+00, 1.1680e-27, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       requires_grad=True) \n",
      "grad tensor([[-8.6944e-07, -6.3512e-26, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6944e-07, -7.3608e-13, -3.5240e-06,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "tensor(6.1475e-08, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# #print(rf.shape)\n",
    "# for a in rf.conv.weight:\n",
    "#     #plt.figure()\n",
    "#     plt.imshow(a[0].detach().numpy())\n",
    "\n",
    "rf = SpatialReceptiveField2d(1, 1, 2, 2, 9)\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = True\n",
    "target = spatial_receptive_field(torch.tensor(1.), torch.tensor(.2), torch.tensor(9), torch.tensor(1))\n",
    "inp = torch.ones((1, 9,9))\n",
    "\n",
    "a = rf.conv.weight\n",
    "for i in range(100):\n",
    "\n",
    "    start = time.time()\n",
    "    out = rf(inp)\n",
    "    end = time.time() - start\n",
    "    l = loss(target, sum(sum(out)))\n",
    "    l.backward()\n",
    "    print(\"attr:\", rf.gf_attr, \"\\ngrad\", rf.gf_attr.grad)\n",
    "    diff(rf, )\n",
    "\n",
    "print((rf.conv.weight - a).sum())\n",
    "#print(rf.angles, rf.log_scales, rf.ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ed71c72-1fb4-4063-be8e-4887e97fc76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.0679536]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAXh0lEQVR4nO3df2xVd/3H8delpYc62yu/CjS0wFDHaCkDCgQ6N+YYpF8gzBh0SxcrGKOzDLrGxVbDWINwwSjBAJYf2YBkdIBRxrbICNQA4qi0ZSzUKQyncB2DbmbeW7rkAr33+4dfr/YLZZz2vns53fORnGT35BzOOzeMZz73tOf6YrFYTAAAJFifZA8AAOidCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADCR2tMXjEajunjxojIyMuTz+Xr68gCAbojFYmptbVV2drb69Ln1GqXHA3Px4kXl5OT09GUBAAkUDAY1fPjwWx7T44HJyMiQJN2v/1Gq+vb05QEA3XBd13RMv4n/W34rPR6Yf38slqq+SvURGADwlP97euXt3OLgJj8AwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMdCkwGzdu1MiRI9WvXz9NnTpVJ06cSPRcAACPcx2Y3bt3q6KiQsuXL9fJkyc1fvx4zZ49Wy0tLRbzAQA8ynVg1q5dq29/+9tauHChxo4dq02bNukzn/mMXnjhBYv5AAAe5SowV69eVVNTk2bOnPmfP6BPH82cOVPHjx+/6TmRSEThcLjDBgDo/VwF5sMPP1R7e7uGDBnSYf+QIUN06dKlm54TCATk9/vjW05OTtenBQB4hvlPkVVVVSkUCsW3YDBofUkAwB0g1c3BgwYNUkpKii5fvtxh/+XLlzV06NCbnuM4jhzH6fqEAABPcrWCSUtL06RJk1RXVxffF41GVVdXp2nTpiV8OACAd7lawUhSRUWFSktLVVhYqClTpmjdunVqa2vTwoULLeYDAHiU68B8/etf1wcffKBnn31Wly5d0n333afXX3/9hhv/AIBPN18sFov15AXD4bD8fr9maL5SfX178tIAgG66Hrumw9qnUCikzMzMWx7Ls8gAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATLgOzNGjRzVv3jxlZ2fL5/Pp5ZdfNhgLAOB1rgPT1tam8ePHa+PGjRbzAAB6iVS3JxQXF6u4uNhiFgBAL+I6MG5FIhFFIpH463A4bH1JAMAdwPwmfyAQkN/vj285OTnWlwQA3AHMA1NVVaVQKBTfgsGg9SUBAHcA84/IHMeR4zjWlwEA3GH4PRgAgAnXK5grV67o3Llz8dd//etfderUKQ0YMEC5ubkJHQ4A4F2uA9PY2KiHHnoo/rqiokKSVFpaqu3btydsMACAt7kOzIwZMxSLxSxmAQD0ItyDAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAnzb7QE7nS+VG/8bxC7fj3ZIwCusIIBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMCEq8AEAgFNnjxZGRkZysrK0qOPPqozZ85YzQYA8DBXgTly5IjKyspUX1+vgwcP6tq1a5o1a5ba2tqs5gMAeJSr74p9/fXXO7zevn27srKy1NTUpAceeCChgwEAvK1bX0YeCoUkSQMGDOj0mEgkokgkEn8dDoe7c0kAgEd0+SZ/NBpVeXm5ioqKlJ+f3+lxgUBAfr8/vuXk5HT1kgAAD+lyYMrKytTc3Kxdu3bd8riqqiqFQqH4FgwGu3pJAICHdOkjssWLF+u1117T0aNHNXz48Fse6ziOHMfp0nAAAO9yFZhYLKannnpKe/fu1eHDhzVq1CiruQAAHucqMGVlZaqtrdW+ffuUkZGhS5cuSZL8fr/S09NNBgQAeJOrezA1NTUKhUKaMWOGhg0bFt92795tNR8AwKNcf0QGAMDt4FlkAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMNGlb7QEepMPFk1O9gi3ZdCW48keAXCFFQwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACZcBaampkYFBQXKzMxUZmampk2bpv3791vNBgDwMFeBGT58uFavXq2mpiY1Njbqy1/+subPn68//vGPVvMBADzK1Vcmz5s3r8PrlStXqqamRvX19crLy0voYAAAb3MVmP/W3t6uX/7yl2pra9O0adM6PS4SiSgSicRfh8Phrl4SAOAhrm/ynz59Wp/97GflOI6++93vau/evRo7dmynxwcCAfn9/viWk5PTrYEBAN7gOjD33HOPTp06pT/84Q968sknVVpaqrfffrvT46uqqhQKheJbMBjs1sAAAG9w/RFZWlqaPv/5z0uSJk2apIaGBv385z/X5s2bb3q84zhyHKd7UwIAPKfbvwcTjUY73GMBAEByuYKpqqpScXGxcnNz1draqtraWh0+fFgHDhywmg8A4FGuAtPS0qJvfOMbev/99+X3+1VQUKADBw7okUcesZoPAOBRrgLz/PPPW80BAOhleBYZAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATLj+Rkugt2l6ribZI9yW2VvuS/YIgCusYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMNGtwKxevVo+n0/l5eUJGgcA0Ft0OTANDQ3avHmzCgoKEjkPAKCX6FJgrly5opKSEm3dulX9+/dP9EwAgF6gS4EpKyvTnDlzNHPmzE88NhKJKBwOd9gAAL1fqtsTdu3apZMnT6qhoeG2jg8EAqqurnY9GADA21ytYILBoJYuXaqdO3eqX79+t3VOVVWVQqFQfAsGg10aFADgLa5WME1NTWppadHEiRPj+9rb23X06FFt2LBBkUhEKSkpHc5xHEeO4yRmWgCAZ7gKzMMPP6zTp0932Ldw4UKNGTNGP/jBD26ICwDg08tVYDIyMpSfn99h31133aWBAwfesB8A8OnGb/IDAEy4/imy/+/w4cMJGAMA0NuwggEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAICJbj9NGfC6Sc89mewRbssgHU/2CIArrGAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADDhKjDPPfecfD5fh23MmDFWswEAPMz1N1rm5eXp0KFD//kDUvlSTADAjVzXITU1VUOHDrWYBQDQi7i+B/POO+8oOztbd999t0pKSnThwgWLuQAAHudqBTN16lRt375d99xzj95//31VV1frS1/6kpqbm5WRkXHTcyKRiCKRSPx1OBzu3sQAAE9wFZji4uL4fxcUFGjq1KkaMWKE9uzZo29961s3PScQCKi6urp7UwIAPKdbP6b8uc99Tl/84hd17ty5To+pqqpSKBSKb8FgsDuXBAB4RLcCc+XKFf3lL3/RsGHDOj3GcRxlZmZ22AAAvZ+rwHz/+9/XkSNH9Le//U1vvPGGvvKVryglJUWPP/641XwAAI9ydQ/m73//ux5//HH94x//0ODBg3X//fervr5egwcPtpoPAOBRrgKza9cuqzkAAL0MzyIDAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADDh6nH9QG80+IWGZI9wW2LJHgBwiRUMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMOE6MO+9956eeOIJDRw4UOnp6Ro3bpwaGxstZgMAeJirLxz76KOPVFRUpIceekj79+/X4MGD9c4776h///5W8wEAPMpVYNasWaOcnBxt27Ytvm/UqFEJHwoA4H2uPiJ75ZVXVFhYqAULFigrK0sTJkzQ1q1brWYDAHiYq8C8++67qqmp0Re+8AUdOHBATz75pJYsWaIdO3Z0ek4kElE4HO6wAQB6P1cfkUWjURUWFmrVqlWSpAkTJqi5uVmbNm1SaWnpTc8JBAKqrq7u/qQAAE9xtYIZNmyYxo4d22HfvffeqwsXLnR6TlVVlUKhUHwLBoNdmxQA4CmuVjBFRUU6c+ZMh31nz57ViBEjOj3HcRw5jtO16QAAnuVqBfP000+rvr5eq1at0rlz51RbW6stW7aorKzMaj4AgEe5CszkyZO1d+9evfTSS8rPz9eKFSu0bt06lZSUWM0HAPAoVx+RSdLcuXM1d+5ci1kAAL0IzyIDAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADDh+nH9QG8Tu3492SMAvRIrGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATLgKzMiRI+Xz+W7YysrKrOYDAHiUq2+0bGhoUHt7e/x1c3OzHnnkES1YsCDhgwEAvM1VYAYPHtzh9erVqzV69Gg9+OCDCR0KAOB9rgLz365evaoXX3xRFRUV8vl8nR4XiUQUiUTir8PhcFcvCQDwkC7f5H/55Zf1z3/+U9/85jdveVwgEJDf749vOTk5Xb0kAMBDfLFYLNaVE2fPnq20tDS9+uqrtzzuZiuYnJwczdB8pfr6duXSAIAkuR67psPap1AopMzMzFse26WPyM6fP69Dhw7p17/+9Sce6ziOHMfpymUAAB7WpY/Itm3bpqysLM2ZMyfR8wAAegnXgYlGo9q2bZtKS0uVmtrlnxEAAPRyrgNz6NAhXbhwQYsWLbKYBwDQS7hegsyaNUtd/LkAAMCnCM8iAwCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADDhKjDt7e1atmyZRo0apfT0dI0ePVorVqxQLBazmg8A4FGpbg5es2aNampqtGPHDuXl5amxsVELFy6U3+/XkiVLrGYEAHiQq8C88cYbmj9/vubMmSNJGjlypF566SWdOHHCZDgAgHe5+ohs+vTpqqur09mzZyVJb731lo4dO6bi4uJOz4lEIgqHwx02AEDv52oFU1lZqXA4rDFjxiglJUXt7e1auXKlSkpKOj0nEAiourq624MCALzF1Qpmz5492rlzp2pra3Xy5Ent2LFDP/3pT7Vjx45Oz6mqqlIoFIpvwWCw20MDAO58rlYwzzzzjCorK/XYY49JksaNG6fz588rEAiotLT0puc4jiPHcbo/KQDAU1ytYD7++GP16dPxlJSUFEWj0YQOBQDwPlcrmHnz5mnlypXKzc1VXl6e3nzzTa1du1aLFi2ymg8A4FGuArN+/XotW7ZM3/ve99TS0qLs7Gx95zvf0bPPPms1HwDAo3yxHv41/HA4LL/frxmar1Rf3568NACgm67Hrumw9ikUCikzM/OWx/IsMgCACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADAhKunKSfCv5+teV3XpB59zCYAoLuu65qk//xbfis9HpjW1lZJ0jH9pqcvDQBIkNbWVvn9/lse0+OP649Go7p48aIyMjLk8/m6/eeFw2Hl5OQoGAx+4qOj0Tnex8TgfUwc3svESPT7GIvF1Nraquzs7Bu+4fj/6/EVTJ8+fTR8+PCE/7mZmZn8JUwA3sfE4H1MHN7LxEjk+/hJK5d/4yY/AMAEgQEAmPB8YBzH0fLly+U4TrJH8TTex8TgfUwc3svESOb72OM3+QEAnw6eX8EAAO5MBAYAYILAAABMEBgAgAnPB2bjxo0aOXKk+vXrp6lTp+rEiRPJHslTAoGAJk+erIyMDGVlZenRRx/VmTNnkj2W561evVo+n0/l5eXJHsVz3nvvPT3xxBMaOHCg0tPTNW7cODU2NiZ7LE9pb2/XsmXLNGrUKKWnp2v06NFasWLFbT0/LJE8HZjdu3eroqJCy5cv18mTJzV+/HjNnj1bLS0tyR7NM44cOaKysjLV19fr4MGDunbtmmbNmqW2trZkj+ZZDQ0N2rx5swoKCpI9iud89NFHKioqUt++fbV//369/fbb+tnPfqb+/fsnezRPWbNmjWpqarRhwwb96U9/0po1a/STn/xE69ev79E5PP1jylOnTtXkyZO1YcMGSf96zllOTo6eeuopVVZWJnk6b/rggw+UlZWlI0eO6IEHHkj2OJ5z5coVTZw4Ub/4xS/04x//WPfdd5/WrVuX7LE8o7KyUr///e/1u9/9LtmjeNrcuXM1ZMgQPf/88/F9X/3qV5Wenq4XX3yxx+bw7Arm6tWrampq0syZM+P7+vTpo5kzZ+r48eNJnMzbQqGQJGnAgAFJnsSbysrKNGfOnA5/L3H7XnnlFRUWFmrBggXKysrShAkTtHXr1mSP5TnTp09XXV2dzp49K0l66623dOzYMRUXF/foHD3+sMtE+fDDD9Xe3q4hQ4Z02D9kyBD9+c9/TtJU3haNRlVeXq6ioiLl5+cnexzP2bVrl06ePKmGhoZkj+JZ7777rmpqalRRUaEf/vCHamho0JIlS5SWlqbS0tJkj+cZlZWVCofDGjNmjFJSUtTe3q6VK1eqpKSkR+fwbGCQeGVlZWpubtaxY8eSPYrnBINBLV26VAcPHlS/fv2SPY5nRaNRFRYWatWqVZKkCRMmqLm5WZs2bSIwLuzZs0c7d+5UbW2t8vLydOrUKZWXlys7O7tH30fPBmbQoEFKSUnR5cuXO+y/fPmyhg4dmqSpvGvx4sV67bXXdPToUZOvU+jtmpqa1NLSookTJ8b3tbe36+jRo9qwYYMikYhSUlKSOKE3DBs2TGPHju2w795779WvfvWrJE3kTc8884wqKyv12GOPSZLGjRun8+fPKxAI9GhgPHsPJi0tTZMmTVJdXV18XzQaVV1dnaZNm5bEybwlFotp8eLF2rt3r377299q1KhRyR7Jkx5++GGdPn1ap06dim+FhYUqKSnRqVOniMttKioquuHH5M+ePasRI0YkaSJv+vjjj2/4MrCUlBRFo9EencOzKxhJqqioUGlpqQoLCzVlyhStW7dObW1tWrhwYbJH84yysjLV1tZq3759ysjI0KVLlyT96wuF0tPTkzydd2RkZNxw3+quu+7SwIEDuZ/lwtNPP63p06dr1apV+trXvqYTJ05oy5Yt2rJlS7JH85R58+Zp5cqVys3NVV5ent58802tXbtWixYt6tlBYh63fv36WG5ubiwtLS02ZcqUWH19fbJH8hRJN922bduW7NE878EHH4wtXbo02WN4zquvvhrLz8+POY4TGzNmTGzLli3JHslzwuFwbOnSpbHc3NxYv379YnfffXfsRz/6USwSifToHJ7+PRgAwJ3Ls/dgAAB3NgIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADAxP8CyKmWvheEDTEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAX8ElEQVR4nO3df2xVd/3H8dfllh7qbK/AaKGhBYZzjPJjQIFA58Ycg/QLhBmDbuliBWMUy4A1LrYaxgjCBaMEA1h+ZALJ6ACjjG2REagBxK1SylioU36IwnUMupl5L3TJBe693z++X69WfpTT3ncvp3s+kpPsnpzT884N2TOfe9pzfYlEIiEAAFKsW7oHAAB0TQQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYyOjsC8bjcV24cEHZ2dny+XydfXkAQAckEgldvnxZ+fn56tbt9muUTg/MhQsXVFBQ0NmXBQCkUCgUUv/+/W97TKcHJjs7W5L0sP5HGere2ZcHAHTAdV3TYf0m+f/y2+n0wPzrY7EMdVeGj8AAgKf8/9Mr7+QWBzf5AQAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYKJdgVm3bp0GDhyoHj16aPz48Tpy5Eiq5wIAeJzrwOzYsUOVlZVavHixjh07ppEjR2rq1Klqbm62mA8A4FGuA7Nq1Sp961vf0uzZszV06FCtX79en/nMZ/SLX/zCYj4AgEe5CszVq1fV2NioyZMn//sHdOumyZMn6+23377pOdFoVJFIpNUGAOj6XAXmo48+UiwWU15eXqv9eXl5unjx4k3PCQaDCgQCya2goKD90wIAPMP8t8iqq6sVDoeTWygUsr4kAOAukOHm4HvvvVd+v1+XLl1qtf/SpUvq27fvTc9xHEeO47R/QgCAJ7lawWRmZmrMmDGqq6tL7ovH46qrq9OECRNSPhwAwLtcrWAkqbKyUuXl5SouLta4ceO0evVqtbS0aPbs2RbzAQA8ynVgvva1r+nDDz/UCy+8oIsXL+qhhx7Sm2++ecONfwDAp5svkUgkOvOCkUhEgUBAkzRTGb7unXlpAEAHXU9c0wHtVjgcVk5Ozm2P5VlkAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACZcB+bQoUOaMWOG8vPz5fP59OqrrxqMBQDwOteBaWlp0ciRI7Vu3TqLeQAAXUSG2xNKS0tVWlpqMQsAoAtxHRi3otGootFo8nUkErG+JADgLmB+kz8YDCoQCCS3goIC60sCAO4C5oGprq5WOBxObqFQyPqSAIC7gPlHZI7jyHEc68sAAO4y/B0MAMCE6xXMlStXdObMmeTrv/71rzp+/Lh69eqlwsLClA4HAPAu14E5evSoHnvsseTryspKSVJ5ebm2bNmSssEAAN7mOjCTJk1SIpGwmAUA0IVwDwYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmzL/REp9yPl+6J2iTz+9P9wh3JBGLpXuEtvGkdfwHVjAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJhwFZhgMKixY8cqOztbubm5evLJJ3Xy5Emr2QAAHuYqMAcPHlRFRYXq6+u1b98+Xbt2TVOmTFFLS4vVfAAAj3L1lclvvvlmq9dbtmxRbm6uGhsb9cgjj6R0MACAt7kKzH8Lh8OSpF69et3ymGg0qmg0mnwdiUQ6ckkAgEe0+yZ/PB7XwoULVVJSomHDht3yuGAwqEAgkNwKCgrae0kAgIe0OzAVFRVqamrS9u3bb3tcdXW1wuFwcguFQu29JADAQ9r1Edm8efP0xhtv6NChQ+rfv/9tj3UcR47jtGs4AIB3uQpMIpHQs88+q127dunAgQMaNGiQ1VwAAI9zFZiKigrV1tZq9+7dys7O1sWLFyVJgUBAWVlZJgMCALzJ1T2YmpoahcNhTZo0Sf369UtuO3bssJoPAOBRrj8iAwDgTvAsMgCACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJho1zda4i7h86V7gjb5778v3SO06dKk3HSPcEfyDjSne4Q2xU6fTfcIbeOp8J2GFQwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACZcBaampkYjRoxQTk6OcnJyNGHCBO3Zs8dqNgCAh7kKTP/+/bVixQo1Njbq6NGj+tKXvqSZM2fqj3/8o9V8AACPcvWVyTNmzGj1etmyZaqpqVF9fb2KiopSOhgAwNtcBeY/xWIx/fKXv1RLS4smTJhwy+Oi0aii0WjydSQSae8lAQAe4vom/4kTJ/TZz35WjuPoO9/5jnbt2qWhQ4fe8vhgMKhAIJDcCgoKOjQwAMAbXAfmgQce0PHjx/WHP/xBc+fOVXl5ud57771bHl9dXa1wOJzcQqFQhwYGAHiD64/IMjMz9fnPf16SNGbMGDU0NOhnP/uZNmzYcNPjHceR4zgdmxIA4Dkd/juYeDze6h4LAACSyxVMdXW1SktLVVhYqMuXL6u2tlYHDhzQ3r17reYDAHiUq8A0Nzfr61//uj744AMFAgGNGDFCe/fu1RNPPGE1HwDAo1wF5qWXXrKaAwDQxfAsMgCACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJhw/Y2WuHv4/P50j9CmS5Ny0z1CmxpfrEn3CHdkzItz0z1Cm/qcPZfuEdqUuH493SN8arCCAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADARIcCs2LFCvl8Pi1cuDBF4wAAuop2B6ahoUEbNmzQiBEjUjkPAKCLaFdgrly5orKyMm3atEk9e/ZM9UwAgC6gXYGpqKjQtGnTNHny5DaPjUajikQirTYAQNeX4faE7du369ixY2poaLij44PBoJYsWeJ6MACAt7lawYRCIS1YsEDbtm1Tjx497uic6upqhcPh5BYKhdo1KADAW1ytYBobG9Xc3KzRo0cn98ViMR06dEhr165VNBqV3+9vdY7jOHIcJzXTAgA8w1VgHn/8cZ04caLVvtmzZ2vIkCH6/ve/f0NcAACfXq4Ck52drWHDhrXad88996h379437AcAfLrxl/wAABOuf4vsvx04cCAFYwAAuhpWMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADDR4acpI30SsVi6R2hT3oHmdI/QpjEvzk33CHfEC+9lzAP/JtF5WMEAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGDCVWBefPFF+Xy+VtuQIUOsZgMAeJjrb7QsKirS/v37//0DMvhSTADAjVzXISMjQ3379rWYBQDQhbi+B3P69Gnl5+frvvvuU1lZmc6fP28xFwDA41ytYMaPH68tW7bogQce0AcffKAlS5boi1/8opqampSdnX3Tc6LRqKLRaPJ1JBLp2MQAAE9wFZjS0tLkf48YMULjx4/XgAEDtHPnTn3zm9+86TnBYFBLlizp2JQAAM/p0K8pf+5zn9MXvvAFnTlz5pbHVFdXKxwOJ7dQKNSRSwIAPKJDgbly5Yr+8pe/qF+/frc8xnEc5eTktNoAAF2fq8B873vf08GDB/W3v/1Nb731lr785S/L7/fr6aeftpoPAOBRru7B/P3vf9fTTz+tf/zjH+rTp48efvhh1dfXq0+fPlbzAQA8ylVgtm/fbjUHAKCL4VlkAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmXD2uH3eZRCLdE7QpdvpsukdoU5+z59I9wh2JxWLpHqFtHvg3ic7DCgYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYcB2Y999/X88884x69+6trKwsDR8+XEePHrWYDQDgYa6+cOzjjz9WSUmJHnvsMe3Zs0d9+vTR6dOn1bNnT6v5AAAe5SowK1euVEFBgTZv3pzcN2jQoJQPBQDwPlcfkb322msqLi7WrFmzlJubq1GjRmnTpk1WswEAPMxVYM6ePauamhrdf//92rt3r+bOnav58+dr69attzwnGo0qEom02gAAXZ+rj8ji8biKi4u1fPlySdKoUaPU1NSk9evXq7y8/KbnBINBLVmypOOTAgA8xdUKpl+/fho6dGirfQ8++KDOnz9/y3Oqq6sVDoeTWygUat+kAABPcbWCKSkp0cmTJ1vtO3XqlAYMGHDLcxzHkeM47ZsOAOBZrlYwzz33nOrr67V8+XKdOXNGtbW12rhxoyoqKqzmAwB4lKvAjB07Vrt27dIrr7yiYcOGaenSpVq9erXKysqs5gMAeJSrj8gkafr06Zo+fbrFLACALoRnkQEATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmHD9uH7AlUQi3RO0KXH9erpHALokVjAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJhwFZiBAwfK5/PdsFVUVFjNBwDwKFffaNnQ0KBYLJZ83dTUpCeeeEKzZs1K+WAAAG9zFZg+ffq0er1ixQoNHjxYjz76aEqHAgB4n6vA/KerV6/q5ZdfVmVlpXw+3y2Pi0ajikajydeRSKS9lwQAeEi7b/K/+uqr+uc//6lvfOMbtz0uGAwqEAgkt4KCgvZeEgDgIb5EIpFoz4lTp05VZmamXn/99dsed7MVTEFBgSZppjJ83dtzaQBAmlxPXNMB7VY4HFZOTs5tj23XR2Tnzp3T/v379etf/7rNYx3HkeM47bkMAMDD2vUR2ebNm5Wbm6tp06aleh4AQBfhOjDxeFybN29WeXm5MjLa/TsCAIAuznVg9u/fr/Pnz2vOnDkW8wAAugjXS5ApU6aonb8XAAD4FOFZZAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmXAUmFotp0aJFGjRokLKysjR48GAtXbpUiUTCaj4AgEdluDl45cqVqqmp0datW1VUVKSjR49q9uzZCgQCmj9/vtWMAAAPchWYt956SzNnztS0adMkSQMHDtQrr7yiI0eOmAwHAPAuVx+RTZw4UXV1dTp16pQk6d1339Xhw4dVWlp6y3Oi0agikUirDQDQ9blawVRVVSkSiWjIkCHy+/2KxWJatmyZysrKbnlOMBjUkiVLOjwoAMBbXK1gdu7cqW3btqm2tlbHjh3T1q1b9ZOf/ERbt2695TnV1dUKh8PJLRQKdXhoAMDdz9UK5vnnn1dVVZWeeuopSdLw4cN17tw5BYNBlZeX3/Qcx3HkOE7HJwUAeIqrFcwnn3yibt1an+L3+xWPx1M6FADA+1ytYGbMmKFly5apsLBQRUVFeuedd7Rq1SrNmTPHaj4AgEe5CsyaNWu0aNEiffe731Vzc7Py8/P17W9/Wy+88ILVfAAAj/IlOvnP8CORiAKBgCZppjJ83Tvz0gCADrqeuKYD2q1wOKycnJzbHsuzyAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAE66eppwK/3q25nVdkzr1MZsAgI66rmuS/v3/8tvp9MBcvnxZknRYv+nsSwMAUuTy5csKBAK3PabTH9cfj8d14cIFZWdny+fzdfjnRSIRFRQUKBQKtfnoaNwa72Nq8D6mDu9laqT6fUwkErp8+bLy8/Nv+Ibj/9bpK5hu3bqpf//+Kf+5OTk5/CNMAd7H1OB9TB3ey9RI5fvY1srlX7jJDwAwQWAAACY8HxjHcbR48WI5jpPuUTyN9zE1eB9Th/cyNdL5Pnb6TX4AwKeD51cwAIC7E4EBAJggMAAAEwQGAGDC84FZt26dBg4cqB49emj8+PE6cuRIukfylGAwqLFjxyo7O1u5ubl68skndfLkyXSP5XkrVqyQz+fTwoUL0z2K57z//vt65pln1Lt3b2VlZWn48OE6evRousfylFgspkWLFmnQoEHKysrS4MGDtXTp0jt6flgqeTowO3bsUGVlpRYvXqxjx45p5MiRmjp1qpqbm9M9mmccPHhQFRUVqq+v1759+3Tt2jVNmTJFLS0t6R7NsxoaGrRhwwaNGDEi3aN4zscff6ySkhJ1795de/bs0Xvvvaef/vSn6tmzZ7pH85SVK1eqpqZGa9eu1Z/+9CetXLlSP/7xj7VmzZpOncPTv6Y8fvx4jR07VmvXrpX0f885Kygo0LPPPquqqqo0T+dNH374oXJzc3Xw4EE98sgj6R7Hc65cuaLRo0fr5z//uX70ox/poYce0urVq9M9lmdUVVXp97//vX73u9+lexRPmz59uvLy8vTSSy8l933lK19RVlaWXn755U6bw7MrmKtXr6qxsVGTJ09O7uvWrZsmT56st99+O42TeVs4HJYk9erVK82TeFNFRYWmTZvW6t8l7txrr72m4uJizZo1S7m5uRo1apQ2bdqU7rE8Z+LEiaqrq9OpU6ckSe+++64OHz6s0tLSTp2j0x92mSofffSRYrGY8vLyWu3Py8vTn//85zRN5W3xeFwLFy5USUmJhg0blu5xPGf79u06duyYGhoa0j2KZ509e1Y1NTWqrKzUD37wAzU0NGj+/PnKzMxUeXl5usfzjKqqKkUiEQ0ZMkR+v1+xWEzLli1TWVlZp87h2cAg9SoqKtTU1KTDhw+nexTPCYVCWrBggfbt26cePXqkexzPisfjKi4u1vLlyyVJo0aNUlNTk9avX09gXNi5c6e2bdum2tpaFRUV6fjx41q4cKHy8/M79X30bGDuvfde+f1+Xbp0qdX+S5cuqW/fvmmayrvmzZunN954Q4cOHTL5OoWurrGxUc3NzRo9enRyXywW06FDh7R27VpFo1H5/f40TugN/fr109ChQ1vte/DBB/WrX/0qTRN50/PPP6+qqio99dRTkqThw4fr3LlzCgaDnRoYz96DyczM1JgxY1RXV5fcF4/HVVdXpwkTJqRxMm9JJBKaN2+edu3apd/+9rcaNGhQukfypMcff1wnTpzQ8ePHk1txcbHKysp0/Phx4nKHSkpKbvg1+VOnTmnAgAFpmsibPvnkkxu+DMzv9ysej3fqHJ5dwUhSZWWlysvLVVxcrHHjxmn16tVqaWnR7Nmz0z2aZ1RUVKi2tla7d+9Wdna2Ll68KOn/vlAoKysrzdN5R3Z29g33re655x717t2b+1kuPPfcc5o4caKWL1+ur371qzpy5Ig2btyojRs3pns0T5kxY4aWLVumwsJCFRUV6Z133tGqVas0Z86czh0k4XFr1qxJFBYWJjIzMxPjxo1L1NfXp3skT5F0023z5s3pHs3zHn300cSCBQvSPYbnvP7664lhw4YlHMdJDBkyJLFx48Z0j+Q5kUgksWDBgkRhYWGiR48eifvuuy/xwx/+MBGNRjt1Dk//HQwA4O7l2XswAIC7G4EBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBg4n8Bs3m3eDS5NcMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print((sum(out[:]).detach().numpy()))\n",
    "for i in rf.conv.weight:\n",
    "    plt.figure()\n",
    "    plt.imshow(((i[0].detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aea4dd2b-ad2c-4acd-a31e-82235df5e43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2214e+00, 0.0000e+00, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2920e+00, 2.3238e-09, 1.0295e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 2.0000e-01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2214e+00, 1.5708e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(target)\n",
    "print(rf.gf_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "db33f9bb-5320-4c78-aedb-6b9c0ff26254",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0653d2a1-03ed-4b4e-b8c9-57a2c94977a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None tensor([-12.,  -8.])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad, b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "144be25d-e021-46c7-a970-f9d317bbda8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r grad: tensor([[ 2.3669e-04, -1.7095e-05],\n",
      "        [ 1.6632e-01, -3.8603e-03]])\n",
      "angle grad: None\n",
      "ratio grad: None\n",
      "scale grad: tensor(-0.0365)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def gaussian_kernel(x, s, c):\n",
    "    \"\"\"\n",
    "    Efficiently creates a 2d gaussian kernel.\n",
    "\n",
    "    Arguments:\n",
    "      x (torch.Tensor): A 2-d matrix\n",
    "      s (float): The variance of the gaussian\n",
    "      c (torch.Tensor): A 2x2 covariance matrix describing the eccentricity of the gaussian\n",
    "    \"\"\"\n",
    "    ci = torch.linalg.inv(c)\n",
    "    cd = torch.linalg.det(c)\n",
    "    fraction = 1 / (2 * torch.pi * s * torch.sqrt(cd))\n",
    "    b = torch.einsum(\"bimj,jk->bik\", -x.unsqueeze(2), ci)\n",
    "    a = torch.einsum(\"bij,bij->bi\", b, x)\n",
    "    return fraction * torch.exp(a / (2 * s))\n",
    "\n",
    "s = torch.tensor(2., requires_grad=True)\n",
    "ratio = torch.tensor(.2, requires_grad=True)\n",
    "sm = torch.tensor([s, s * ratio], requires_grad=True)\n",
    "x = torch.linspace(-5, 5, 11)\n",
    "x = torch.unsqueeze(x, 0).repeat(11, 1)\n",
    "x = torch.stack((x, x.T))\n",
    "x = torch.einsum(\"abc->bca\",x)\n",
    "angle = torch.tensor(np.pi/3, requires_grad=True)\n",
    "r = torch.tensor(\n",
    "    [[torch.cos(angle), torch.sin(angle)], [-torch.sin(angle), torch.cos(angle)]],\n",
    "    dtype=torch.float32, requires_grad=True\n",
    ")\n",
    "\n",
    "c = (r * sm) @ (sm * r).T\n",
    "\n",
    "a = gaussian_kernel(x, s, c)\n",
    "plt.imshow(a.detach().numpy())\n",
    "a.sum().backward()\n",
    "\n",
    "print(\"r grad:\", r.grad)\n",
    "print(\"angle grad:\", angle.grad)\n",
    "print(\"ratio grad:\", ratio.grad)\n",
    "print(\"scale grad:\", s.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5835ed23-7aa4-418d-89f7-84fe196efb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MmBackward0 object at 0x7f1f1441c3d0>\n"
     ]
    }
   ],
   "source": [
    "print(c.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9785f3c2-11f8-4429-a6a3-5e3cba785b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "angle = torch.tensor(np.pi/3, requires_grad=True)\n",
    "r = torch.tensor([[torch.cos(angle), torch.sin(angle)], [-torch.sin(angle), torch.cos(angle)]], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "r.sum().backward()\n",
    "print(angle.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "403b7199-cc3e-4a26-9ce0-eda79b86d187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "angle = torch.tensor(np.pi/3, requires_grad=True)\n",
    "b=torch.tensor([torch.sin(angle)], dtype=torch.float32, requires_grad=True)\n",
    "b.sum().backward()\n",
    "print(b.grad)\n",
    "print(angle.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a2aa0b9b-97a2-4f77-b452-c492c1850e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is angle a leaf variable? True\n",
      "Is b a leaf variable? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "angle = torch.tensor(np.pi/3, requires_grad=True)\n",
    "b = torch.tensor([angle.sin()], dtype=torch.float32)\n",
    "\n",
    "# Use the in-place sin_ operation\n",
    "b.sin_()\n",
    "\n",
    "print(\"Is angle a leaf variable?\", angle.is_leaf)  # True\n",
    "print(\"Is b a leaf variable?\", b.is_leaf)          # False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "666a2f48-7286-4d19-b15b-a93bbe661584",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = torch.tensor([np.pi/3, 1], requires_grad=True)\n",
    "ratio = torch.tensor([np.pi/3, 1], requires_grad=True)\n",
    "scale = torch.tensor([np.pi/3, 1], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fd8f6188-20fa-4dfc-b71c-ff1cdd93fafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.2705e-11, -3.0393e-12])\n"
     ]
    }
   ],
   "source": [
    "spatial_receptive_fields_with_derivatives(scale, angle, ratio, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53afa05a-c2ec-43d4-bd25-4be14e06d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Method 2\n",
    "\n",
    "\"\"\"\n",
    "These receptive fields are derived from scale-space theory, specifically in the paper `Normative theory of visual receptive fields by Lindeberg, 2021 <https://www.sciencedirect.com/science/article/pii/S2405844021000025>`_.\n",
    "\n",
    "For use in spiking / binary signals, see the paper on `Translation and Scale Invariance for Event-Based Object tracking by Pedersen et al., 2023 <https://dl.acm.org/doi/10.1145/3584954.3584996>`_\n",
    "\"\"\"\n",
    "\n",
    "from typing import Callable, List, NamedTuple, Optional, Tuple, Type, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "#from norse.torch.module.leaky_integrator_box import LIBoxCell, LIBoxParameters\n",
    "from norse.torch.module.snn import SNNCell\n",
    "\n",
    "\n",
    "\n",
    "class SpatialReceptiveField2d(torch.nn.Module):\n",
    "    \"\"\"Creates a spatial receptive field as 2-dimensional convolutions.\n",
    "    The parameters decide the number of combinations to scan over, i. e. the number of receptive fields to generate.\n",
    "    Specifically, we generate ``n_scales * n_angles * (n_ratios - 1) + n_scales`` output_channels with aggregation,\n",
    "    and ``in_channels * (n_scales * n_angles * (n_ratios - 1) + n_scales)`` without aggregation.\n",
    "\n",
    "    The ``(n_ratios - 1) + n_scales`` terms exist because at ``ratio = 1``, fields are perfectly symmetrical, and there\n",
    "    is therefore no reason to scan over the angles and scales for ``ratio = 1``.\n",
    "    However, ``n_scales`` receptive field still needs to be added (one for each scale-space).\n",
    "\n",
    "    Parameters:\n",
    "        n_scales (int): Number of scaling combinations (the size of the receptive field) drawn from a logarithmic distribution\n",
    "        n_angles (int): Number of angular combinations (the orientation of the receptive field)\n",
    "        n_ratios (int): Number of eccentricity combinations (how \"flat\" the receptive field is)\n",
    "        size (int): The size of the square kernel in pixels\n",
    "        derivatives (Union[int, List[Tuple[int, int]]]): The number of derivatives to use in the receptive field.\n",
    "        aggregate (bool): If True, sums the input channels over all output channels. If False, every\n",
    "        output channel is mapped to every input channel, which may blow up in complexity.\n",
    "        **kwargs: Arguments passed on to the underlying torch.nn.Conv2d\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        n_scales: int,\n",
    "        n_angles: int,\n",
    "        n_ratios: int,\n",
    "        size: int,\n",
    "        derivatives: Union[int, List[Tuple[int, int]]] = 0,\n",
    "        min_scale: float = 0.2,\n",
    "        max_scale: float = 1.5,\n",
    "        min_ratio: float = 0.2,\n",
    "        max_ratio: float = 1,\n",
    "        aggregate: bool = True,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.angles = torch.linspace(0, torch.pi - torch.pi / n_angles, n_angles, requires_grad=True)\n",
    "        self.ratios = torch.linspace(min_ratio, max_ratio, n_ratios, requires_grad=True)\n",
    "        self.log_scales = torch.linspace(min_scale, max_scale, n_scales, requires_grad=True)\n",
    "        self.scales = torch.exp(self.log_scales)\n",
    "        self.size = size\n",
    "        self.derivatives = derivatives\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale \n",
    "        self.min_ratio = min_ratio\n",
    "        self.max_ratio = max_ratio\n",
    "        self.aggregate = aggregate\n",
    "        self.in_channels = in_channels\n",
    "        self.kwargs = kwargs \n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        fields = spatial_receptive_fields_with_derivatives(\n",
    "            self.scales,\n",
    "            self.angles,\n",
    "            self.ratios,\n",
    "            self.size,\n",
    "            self.derivatives,\n",
    "            self.min_scale,\n",
    "            self.max_scale,\n",
    "            self.min_ratio,\n",
    "            self.max_ratio,\n",
    "            **self.kwargs\n",
    "        )\n",
    "        if self.aggregate:\n",
    "            self.out_channels = fields.shape[0]\n",
    "            weights = fields.unsqueeze(1).repeat(1, self.in_channels, 1, 1)\n",
    "        else:\n",
    "            self.out_channels = fields.shape[0] * in_channels\n",
    "            empty_weights = torch.zeros(in_channels, fields.shape[0], self.size, self.size)\n",
    "            weights = []\n",
    "            for i in range(in_channels):\n",
    "                in_weights = empty_weights.clone()\n",
    "                in_weights[i] = fields\n",
    "                weights.append(in_weights)\n",
    "            weights = torch.concat(weights, 1).permute(1, 0, 2, 3)\n",
    "        self.conv = torch.nn.Conv2d(self.in_channels, self.out_channels, self.size, **self.kwargs)\n",
    "        self.conv.weight = torch.nn.Parameter(weights, requires_grad=False)\n",
    "        self.conv.weight[:] = weights[:]\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4ac0fee4-cace-4fad-97a2-193a597f2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([1,0,0,1,1])\n",
    "b = torch.Tensor([1,0,1,1,1])\n",
    "a.requires_grad = True\n",
    "b.requires_grad = True\n",
    "c = a+b\n",
    "d = torch.sum((c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d131792c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SumBackward0 object at 0x7f73132773d0>\n"
     ]
    }
   ],
   "source": [
    "print(d.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b1f461f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., grad_fn=<SumBackward0>)\n",
      "Original tensor c: tensor([1., 0., 1.], requires_grad=True)\n",
      "Resulting sum d: 2.0\n",
      "Gradient of c: tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class custom_eq(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, v):\n",
    "        ctx.save_for_backward(input)\n",
    "        result = torch.eq(input, v).float()\n",
    "        return result\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output, None\n",
    "    \n",
    "\n",
    "# Assuming you have a tensor c\n",
    "c = torch.tensor([1, 0, 1], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# Performing the sum operation using torch.eq\n",
    "d = torch.sum(custom_eq.apply(c, 1))\n",
    "print(d)\n",
    "# Backward pass to compute gradients\n",
    "d.backward()\n",
    "\n",
    "# Accessing the gradient of c\n",
    "gradient_of_c = c.grad\n",
    "\n",
    "print(\"Original tensor c:\", c)\n",
    "print(\"Resulting sum d:\", d.item())\n",
    "print(\"Gradient of c:\", gradient_of_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e912fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "phd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
