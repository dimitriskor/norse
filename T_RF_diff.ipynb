{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035dbb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union, Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "def temporal_scale_distribution(\n",
    "    n_scales: int,\n",
    "    min_scale: float = 1,\n",
    "    max_scale: Optional[float] = None,\n",
    "    c: Optional[float] = 1.41421,\n",
    "):\n",
    "    r\"\"\"\n",
    "    Provides temporal scales according to [Lindeberg2016].\n",
    "    The scales will be logarithmic by default, but can be changed by providing other values for c.\n",
    "\n",
    "    .. math:\n",
    "        \\tau_k = c^{2(k - K)} \\tau_{max}\n",
    "        \\mu_k = \\sqrt(\\tau_k - \\tau_{k - 1})\n",
    "\n",
    "    Arguments:\n",
    "      n_scales (int): Number of scales to generate\n",
    "      min_scale (float): The minimum scale\n",
    "      max_scale (Optional[float]): The maximum scale. Defaults to None. If set, c is ignored.\n",
    "      c (Optional[float]): The base from which to generate scale values. Should be a value\n",
    "        between 1 to 2, exclusive. Defaults to sqrt(2). Ignored if max_scale is set.\n",
    "\n",
    "    .. [Lindeberg2016] Lindeberg 2016, Time-Causal and Time-Recursive Spatio-Temporal\n",
    "        Receptive Fields, https://link.springer.com/article/10.1007/s10851-015-0613-9.\n",
    "    \"\"\"\n",
    "    xs = torch.linspace(1, n_scales, n_scales)\n",
    "    if max_scale is not None:\n",
    "        if n_scales > 1:  # Avoid division by zero when having a single scale\n",
    "            c = (min_scale / max_scale) ** (1 / (2 * (n_scales - 1)))\n",
    "        else:\n",
    "            return torch.tensor([min_scale]).sqrt()\n",
    "    else:\n",
    "        max_scale = (c ** (2 * (n_scales - 1))) * min_scale\n",
    "    taus = c ** (2 * (xs - n_scales)) * max_scale\n",
    "    return taus.sqrt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4238f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, NamedTuple, Optional, Tuple, Type, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "from norse.torch.module.leaky_integrator_box import LIBoxCell, LIBoxParameters\n",
    "from norse.torch.module.snn import SNNCell\n",
    "from norse.torch.functional.receptive_field import (\n",
    "    spatial_receptive_fields_with_derivatives,\n",
    "    temporal_scale_distribution,\n",
    ")\n",
    "\n",
    "class TemporalReceptiveField(torch.nn.Module):\n",
    "    \"\"\"Creates ``n_scales`` temporal receptive fields for arbitrary n-dimensional inputs.\n",
    "    The scale spaces are selected in a range of [min_scale, max_scale] using an exponential distribution, scattered using ``torch.linspace``.\n",
    "\n",
    "    Parameters:\n",
    "        shape (torch.Size): The shape of the incoming tensor, where the first dimension denote channels\n",
    "        n_scales (int): The number of temporal scale spaces to iterate over.\n",
    "        activation (SNNCell): The activation neuron. Defaults to LIBoxCell\n",
    "        activation_state_map (Callable): A function that takes a tensor and provides a neuron parameter tuple.\n",
    "            Required if activation is changed, since the default behaviour provides LIBoxParameters.\n",
    "        min_scale (float): The minimum scale space. Defaults to 1.\n",
    "        max_scale (Optional[float]): The maximum scale. Defaults to None. If set, c is ignored.\n",
    "        c (Optional[float]): The base from which to generate scale values. Should be a value\n",
    "            between 1 to 2, exclusive. Defaults to sqrt(2). Ignored if max_scale is set.\n",
    "        time_constants (Optional[torch.Tensor]): Hardcoded time constants. Will overwrite the automatically generated, logarithmically distributed scales, if set. Defaults to None.\n",
    "        dt (float): Neuron simulation timestep. Defaults to 0.001.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        shape: torch.Size,\n",
    "        n_scales: int = 4,\n",
    "        activation: Type[SNNCell] = LIBoxCell,\n",
    "        activation_state_map: Callable[\n",
    "            [torch.Tensor], NamedTuple\n",
    "        ] = lambda t: LIBoxParameters(tau_mem_inv=t),\n",
    "        min_scale: float = 1,\n",
    "        max_scale: Optional[float] = None,\n",
    "        c: float = 1.41421,\n",
    "        time_constants: Optional[torch.Tensor] = None,\n",
    "        dt: float = 0.001,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if time_constants is None:\n",
    "            taus = (1 / dt) / temporal_scale_distribution(\n",
    "                n_scales, min_scale=min_scale, max_scale=max_scale, c=c\n",
    "            )\n",
    "            self.time_constants = torch.stack(\n",
    "                [\n",
    "                    torch.full(\n",
    "                        [shape[0], *[1 for i in range(len(shape) - 1)]],\n",
    "                        tau,\n",
    "                        dtype=torch.float32,\n",
    "                    )\n",
    "                    for tau in taus\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.time_constants = time_constants\n",
    "        self.ps = torch.nn.Parameter(self.time_constants)\n",
    "        # pytype: disable=missing-parameter\n",
    "        self.neurons = activation(p=activation_state_map(self.ps), dt=dt)\n",
    "        # pytype: enable=missing-parameter\n",
    "        self.rf_dimension = len(shape)\n",
    "        self.n_scales = n_scales\n",
    "\n",
    "    def forward(self, x: torch.Tensor, state: Optional[NamedTuple] = None):\n",
    "        x_repeated = torch.stack(\n",
    "            [x for _ in range(self.n_scales)], dim=-self.rf_dimension - 1\n",
    "        )\n",
    "        return self.neurons(x_repeated, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2a53c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from norse.torch.module.lift import Lift\n",
    "m = (TemporalReceptiveField((1, 1, 10), 3))\n",
    "y, s = m(torch.ones(2, 1, 1, 10)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0bd2d0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1, 1, 10])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5d107626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0707, 0.0707], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,1,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14fabcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
